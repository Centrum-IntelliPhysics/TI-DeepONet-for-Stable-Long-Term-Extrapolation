{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2c3477-9a71-4a31-89d1-6b52d1ca8d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries\n",
    "\n",
    "import os, sys, pickle\n",
    "import jax, jaxlib\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "import optax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Callable, Sequence\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bad965-3b98-4f2c-9348-5953f823ff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Burgers' data\n",
    "burgers = loadmat(\"Burger.mat\")\n",
    "output = burgers['output']\n",
    "burgers.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b30cde1-58c5-41d2-9a47-c93f9b547894",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now, we need to create a training data where input is [(u0, u1, u2, u3, ...., u50)] and\n",
    "output is [(u1, u2, u3,....., u51)]\n",
    "'''\n",
    "\n",
    "#Creating the input and output training data\n",
    "init_timestep = 0\n",
    "end_timestep = 50\n",
    "\n",
    "input_data_NN = output[:,init_timestep,:]\n",
    "output_data_NN = output[:,init_timestep+1,:]\n",
    "\n",
    "for i in range(init_timestep+1, end_timestep):\n",
    "    input_data_NN = jnp.vstack((input_data_NN, output[:,i,:]))\n",
    "    output_data_NN = jnp.vstack((output_data_NN, output[:,i+1,:]))\n",
    "\n",
    "input_data_NN.shape, output_data_NN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a8e0be-26bb-4e55-96fc-49d285afc04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the training and testing data splits\n",
    "input_data_NN_train, input_data_NN_test, output_data_NN_train, output_data_NN_test = \\\n",
    "                        train_test_split(input_data_NN, output_data_NN, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e45dec-523f-4643-80ab-a39664895065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility class for defining the branch network\n",
    "class branch_net(nn.Module):\n",
    "    branch_layer_config: Sequence[int]\n",
    "    activation: Callable\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        init = nn.initializers.glorot_normal()\n",
    "        \n",
    "        #Branch network forward pass\n",
    "        for i, layer_size in enumerate(self.branch_layer_config[:-1]):\n",
    "            x = nn.Dense(layer_size, kernel_init = init)(x)\n",
    "            x = self.activation(x)\n",
    "        x = nn.Dense(self.branch_layer_config[-1], kernel_init = init)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96303dce-7c57-4105-b3d2-02bf329fee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility class for defining the trunk network\n",
    "class trunk_net(nn.Module):\n",
    "    trunk_layer_config: Sequence[int]\n",
    "    activation: Callable\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        init = nn.initializers.glorot_normal()\n",
    "        \n",
    "        #Trunk network forward pass\n",
    "        for i, layer_size in enumerate(self.trunk_layer_config):\n",
    "            x = nn.Dense(layer_size, kernel_init = init)(x)\n",
    "            x = self.activation(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2288c69-dcdd-452c-977e-51046cf151bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the DeepONet model\n",
    "class DeepONet(nn.Module):\n",
    "\n",
    "    branch_net_config: Sequence[int]\n",
    "    trunk_net_config: Sequence[int]\n",
    "\n",
    "    def setup(self):\n",
    "\n",
    "        self.branch_net = branch_net(self.branch_net_config, nn.activation.tanh)\n",
    "        self.trunk_net = trunk_net(self.trunk_net_config, nn.activation.tanh)\n",
    "\n",
    "\n",
    "    def __call__(self, x_branch, x_trunk):\n",
    "        \n",
    "        #Vectorize over multiple samples of input functions\n",
    "        branch_outputs = jax.vmap(self.branch_net, in_axes = 0)(x_branch)\n",
    "        \n",
    "        #Vectorize over multiple query points\n",
    "        trunk_outputs = jax.vmap(self.trunk_net, in_axes = 0)(x_trunk)       \n",
    "        \n",
    "        inner_product = jnp.einsum('ik,jk->ij', branch_outputs, trunk_outputs)\n",
    "\n",
    "        return inner_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1b62a5-5cc6-497f-8db1-ec5ad33a47ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Form branch and trunk inputs train\n",
    "grid = jnp.linspace(0, 1, 101)[:,jnp.newaxis]   #Trunk net takes only spatial coordinates\n",
    "branch_inputs_train = input_data_NN_train\n",
    "trunk_inputs_train = grid\n",
    "outputs_train = output_data_NN_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baed59f1-8d2d-4489-9544-0c10ef87e1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For branch and trunk inputs test\n",
    "branch_inputs_test = input_data_NN_test\n",
    "trunk_inputs_test = grid\n",
    "outputs_test = output_data_NN_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa88bb9-8993-4e35-8bba-92ab72a6ce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DeepONet settings\n",
    "\n",
    "#Define the latent dimension at the output of branch/trunk net\n",
    "latent_vector_size = 60\n",
    "\n",
    "#Create the branch and trunk layer configurations\n",
    "branch_network_layer_sizes = [101] + [100]*6 + [latent_vector_size]\n",
    "trunk_network_layer_sizes = [100]*6 + [latent_vector_size]\n",
    "\n",
    "#Instantiate the DeepONet model\n",
    "model = DeepONet(branch_network_layer_sizes, trunk_network_layer_sizes)\n",
    "\n",
    "#Create a jitted model forward function\n",
    "model_fn = jax.jit(model.apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d041ae7c-e543-4a72-9697-613eae30cc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility function for saving the model parameters\n",
    "def save_model_params(params, path, filename):\n",
    "    \n",
    "    #Create output directory for saving model params\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    \n",
    "    save_path = os.path.join(path, filename)\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(params, f)\n",
    "\n",
    "#Utility function for loading the model parameters\n",
    "def load_model_params(path, filename):\n",
    "    load_path = os.path.join(path, filename)\n",
    "    with open(load_path, 'rb') as f:\n",
    "        params = pickle.load(f)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e14732-d308-4f17-8ec4-6732805f9d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def loss_fn(params, branch_inputs, trunk_inputs, gt_outputs, dt=0.01):\n",
    "    \n",
    "    u_curr = branch_inputs  # Current state input (e.g., u(t))\n",
    "    u_next = gt_outputs     # Ground truth next state (e.g., u(t+1))\n",
    "\n",
    "    # Predict the system dynamics (u_dot) at the current state using the model\n",
    "    u_dot = model_fn(params, u_curr, trunk_inputs)  # Model's predicted rate of change\n",
    "\n",
    "    # Implementing the 4th-order Runge-Kutta (RK4) time-stepping method\n",
    "    k1 = u_dot\n",
    "    k2 = model_fn(params, u_curr + 0.5 * dt * k1, trunk_inputs)\n",
    "    k3 = model_fn(params, u_curr + 0.5 * dt * k2, trunk_inputs)\n",
    "    k4 = model_fn(params, u_curr + dt * k3, trunk_inputs)\n",
    "    \n",
    "    # Calculate the next state using RK4\n",
    "    u_pred_next = u_curr + (dt / 6) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
    "\n",
    "    # Compute the Mean Squared Error loss between the predicted and ground truth next states\n",
    "    mse_loss = jnp.mean(jnp.square(u_pred_next - u_next))\n",
    "    \n",
    "    return mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7304664c-7c89-4992-bafd-71a85d68a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def update(params, branch_inputs, trunk_inputs, gt_outputs, opt_state):\n",
    "    loss, grads = jax.value_and_grad(loss_fn)(params, branch_inputs, trunk_inputs, gt_outputs)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    \n",
    "    return params, opt_state, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc71764-30ac-4e16-9395-ab9b3783602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model parameters\n",
    "key = jax.random.PRNGKey(42)\n",
    "params = model.init(key, branch_inputs_train, trunk_inputs_train)\n",
    "\n",
    "# Optimizer setup\n",
    "lr_scheduler = optax.schedules.exponential_decay(init_value=1e-3, transition_steps=5000, decay_rate=0.95)\n",
    "optimizer = optax.adam(learning_rate=lr_scheduler)\n",
    "opt_state = optimizer.init(params)\n",
    "\n",
    "training_loss_history = []\n",
    "test_loss_history = []\n",
    "num_epochs = int(1e5)\n",
    "batch_size = 256\n",
    "\n",
    "min_test_loss = jnp.inf\n",
    "\n",
    "filepath = 'TI-DON_Burgers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7f1176-64da-4a1a-8501-98105f783299",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc = \"Training progress\"):\n",
    "\n",
    "    #Perform mini-batching\n",
    "    shuffled_indices = jax.random.permutation(jax.random.PRNGKey(epoch), input_data_NN.shape[0])\n",
    "    batch_indices = shuffled_indices[:batch_size]\n",
    "\n",
    "    branch_inputs_train_batch = branch_inputs_train[batch_indices]\n",
    "    outputs_train_batch = outputs_train[batch_indices]\n",
    "\n",
    "    # Update the parameters and optimizer state\n",
    "    params, opt_state, loss = update(\n",
    "        params=params,\n",
    "        branch_inputs=branch_inputs_train_batch,\n",
    "        trunk_inputs=trunk_inputs_train,\n",
    "        gt_outputs=outputs_train_batch,\n",
    "        opt_state=opt_state\n",
    "    )\n",
    "\n",
    "    #Keep a track of the training loss\n",
    "    training_loss_history.append(loss)\n",
    "    \n",
    "    #Do predictions on the test data simultaneously\n",
    "    test_mse_loss = loss_fn(params = params, \n",
    "                            branch_inputs = branch_inputs_test, \n",
    "                            trunk_inputs = trunk_inputs_test, \n",
    "                            gt_outputs = outputs_test)\n",
    "    test_loss_history.append(test_mse_loss)\n",
    "    \n",
    "    #Save the params of the best model encountered till now\n",
    "    if test_mse_loss < min_test_loss:\n",
    "        best_params = params\n",
    "        save_model_params(best_params, path = filepath, filename = 'model_params_best.pkl')\n",
    "        min_test_loss = test_mse_loss\n",
    "    \n",
    "    #Print the train and test loss history every 1000 epochs\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch: {epoch}, training_loss_MSE: {loss}, test_loss_MSE: {test_mse_loss}, \\\n",
    "                                best_test_loss_MSE: {min_test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabb0d4e-3ade-42bd-8cad-b7c4408145cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the train and test loss histories\n",
    "plt.figure(dpi = 130)\n",
    "plt.semilogy(np.arange(epoch+1), training_loss_history, label = \"Train loss\")\n",
    "plt.semilogy(np.arange(epoch+1), test_loss_history, label = \"Test loss\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.tick_params(which = 'major', axis = 'both', direction = 'in', length = 6)\n",
    "plt.tick_params(which = 'minor', axis = 'both', direction = 'in', length = 3.5)\n",
    "plt.minorticks_on()\n",
    "\n",
    "plt.grid(alpha = 0.3)\n",
    "plt.legend(loc = 'best')\n",
    "plt.savefig(filepath + \"/loss_plot.jpeg\", dpi = 800)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c194425-240a-4556-8358-76e7af9c1419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the loss arrays\n",
    "np.save(\"Train_loss.npy\",training_loss_history)\n",
    "np.save(\"Test_loss.npy\",test_loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea9aeb-514a-40be-bd29-e63d10c14761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform AB2/AM3 inferencing for one timestep\n",
    "@jax.jit\n",
    "def inference_ab2_am3(u_curr, u_prev, trunk_inputs_test, dt=0.01):\n",
    "    # Step 1: Apply the predictor (Adams-Bashforth) using u_curr and u_prev\n",
    "    u_dot_curr = model_fn(best_params, u_curr, trunk_inputs_test)  # Predict the rate of change at u_curr\n",
    "    u_dot_prev = model_fn(best_params, u_prev, trunk_inputs_test)  # Predict the rate of change at u_prev\n",
    "    \n",
    "    # Adams-Bashforth predictor (using previous two points)\n",
    "    u_pred = u_curr + dt * (1.5 * u_dot_curr - 0.5 * u_dot_prev)\n",
    "    \n",
    "    # Step 2: Apply the corrector (Adams-Moulton) using the predicted u_pred\n",
    "    u_dot_pred = model_fn(best_params, u_pred, trunk_inputs_test)  # Predict the rate of change at u_pred\n",
    "    \n",
    "    # Adams-Moulton corrector (refine the prediction using u_pred)\n",
    "    u_next = u_curr + dt * (5/12 * u_dot_pred + 8/12 * u_dot_curr - 1/12 * u_dot_prev)\n",
    "    \n",
    "    return u_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f724db35-5d26-401b-a84c-be646853aaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform RK4 inferencing for one timestep\n",
    "@jax.jit\n",
    "def inference_rk(u_curr, trunk_inputs_test, dt = 0.01):\n",
    "    \n",
    "    # Predict the system dynamics (u_dot) at the current state using the model\n",
    "    u_dot = model_fn(params, u_curr, trunk_inputs_test)  # Model's predicted rate of change\n",
    "\n",
    "    # Implementing the 4th-order Runge-Kutta (RK4) time-stepping method\n",
    "    k1 = u_dot\n",
    "    k2 = model_fn(params, u_curr + 0.5 * dt * k1, trunk_inputs_test)\n",
    "    k3 = model_fn(params, u_curr + 0.5 * dt * k2, trunk_inputs_test)\n",
    "    k4 = model_fn(params, u_curr + dt * k3, trunk_inputs_test)\n",
    "    \n",
    "    # Calculate the next state using RK4\n",
    "    u_pred_next = u_curr + (dt / 6) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
    "    \n",
    "    return u_pred_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bb7fe5-3498-430f-823d-98aec102af1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility function for performing inferencing over all timesteps\n",
    "def run_inference(initial_u, trunk_inputs_test, n_steps, method=\"AB\", dt=0.01):\n",
    "    print(f\"Method being used: {method}\")\n",
    "    u_states = np.zeros_like(output)  # Array to store the states over time\n",
    "    u_states[:, 0, :] = initial_u\n",
    "\n",
    "    # Initialize the previous states (this could be your u_0 and u_1, etc.)\n",
    "    u_prev1 = initial_u  # Set the previous state to initial state\n",
    "    u_curr = initial_u  # Set the current state to initial state\n",
    "\n",
    "    if method == \"AB\":\n",
    "        for i in range(1, n_steps):\n",
    "            # Perform inference step using the Adams-Bashforth method\n",
    "            u_next = inference_ab2_am3(u_curr, u_prev1, trunk_inputs_test, dt)\n",
    "            u_states[:, i, :] = u_next\n",
    "\n",
    "            # Update previous and current states for the next step\n",
    "            u_prev1 = u_curr\n",
    "            u_curr = u_next\n",
    "\n",
    "    elif method == \"RK\":\n",
    "        for i in range(1, n_steps):\n",
    "            # Perform inference step using the RK4 method\n",
    "            u_next = inference_rk(u_curr, trunk_inputs_test, dt)\n",
    "            u_states[:, i, :] = u_next\n",
    "\n",
    "            # Update the current state for the next step\n",
    "            u_curr = u_next\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "    return u_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4847ca8d-4db3-406e-a25c-c47f91247568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model parameters\n",
    "best_params = load_model_params(path=filepath, filename='model_params_best.pkl')\n",
    "\n",
    "#Start with u(t=0, x)\n",
    "u_curr = output[:, 0, :]\n",
    "\n",
    "method = \"AB\"\n",
    "\n",
    "#Perform inferencing\n",
    "u_pred = run_inference(u_curr, trunk_inputs_test, n_steps=101, method=method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7096e4ce-ce9a-43e4-afa0-94d3f4de973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly selecting \"size\" number of samples out of the test dataset\n",
    "indices = np.random.choice(np.arange(output.shape[0]), size = 3, replace = 'True')\n",
    "\n",
    "x_test = jnp.linspace(0,1,101)\n",
    "t_test = jnp.linspace(0,1,101)\n",
    "\n",
    "for idx in indices:\n",
    "    plt.figure(figsize = (12,3))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    contour1 = plt.contourf(x_test, t_test, u_pred[idx, :, :], levels = 20, cmap = 'jet')\n",
    "    plt.xlabel(\"x\", fontsize = 14)\n",
    "    plt.ylabel(\"t\", fontsize = 14)\n",
    "    plt.yticks(fontsize = 12)\n",
    "    plt.xticks(fontsize = 12)\n",
    "    cbar1 = plt.colorbar()\n",
    "    cbar1.ax.tick_params(labelsize=12)\n",
    "    plt.title(\"Predicted\", fontsize = 16)\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    contour2 = plt.contourf(x_test, t_test, output[idx, :, :], levels = 20, cmap = 'jet')\n",
    "    plt.xlabel(\"x\", fontsize = 14)\n",
    "    plt.ylabel(\"t\", fontsize = 14)\n",
    "    plt.yticks(fontsize = 12)\n",
    "    plt.xticks(fontsize = 12)\n",
    "    cbar2 = plt.colorbar()\n",
    "    cbar2.ax.tick_params(labelsize=12)\n",
    "    plt.title(\"Actual\", fontsize=16)\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    contour3 = plt.contourf(x_test, t_test, jnp.abs(u_pred[idx, :, :] - output[idx, :, :]), cmap = 'Wistia')\n",
    "    plt.xlabel(\"x\", fontsize = 14)\n",
    "    plt.ylabel(\"t\", fontsize = 14)\n",
    "    plt.yticks(fontsize = 12)\n",
    "    plt.xticks(fontsize = 12)\n",
    "    cbar3 = plt.colorbar()\n",
    "    cbar3.ax.tick_params(labelsize=12)\n",
    "    plt.title(\"Error\", fontsize = 16)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(filepath + f\"/Contour_plots_sidx_{idx}_{method}.jpeg\", dpi = 800)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0040c8c7-8822-4033-ad2e-47af9917eec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the relative L2 error obtained at every timestep to show accummulation of autoregressive error\n",
    "\n",
    "auto_reg_error = []\n",
    "num_time_steps = 101\n",
    "\n",
    "for i in range(num_time_steps):\n",
    "    l2_error = jnp.linalg.norm(u_pred[:,i,:] - output[:,i,:])/jnp.linalg.norm(output[:,i,:])\n",
    "    auto_reg_error.append(l2_error)\n",
    "    \n",
    "plt.plot(jnp.arange(num_time_steps), auto_reg_error)\n",
    "plt.xlabel(\"Timesteps\")\n",
    "plt.ylabel(\"Relative L2 error\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb77273-5aae-433d-9261-65bfc4cda887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the auto_reg_error array for comparing with TI approach\n",
    "np.save(filepath + f\"/Auto_reg_error_with_TI-DON_{method}.npy\", auto_reg_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4faea0-450f-4e52-ac28-eb604d3c4ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the predictions and ground truth outputs\n",
    "\n",
    "np.save(filepath + \"/u_pred.npy\", u_pred)\n",
    "np.save(filepath + \"/u_actual.npy\", output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
