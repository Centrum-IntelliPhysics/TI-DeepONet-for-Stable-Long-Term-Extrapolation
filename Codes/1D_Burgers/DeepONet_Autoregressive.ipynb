{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e9378d-c537-44b4-bc49-84df42a6183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries\n",
    "\n",
    "import os, sys, pickle\n",
    "import jax, jaxlib\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "import optax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Callable, Sequence\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2387426c-7b58-4dce-8d03-9ad24674315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset\n",
    "burgers = loadmat(\"Burger.mat\")\n",
    "output = burgers['output']\n",
    "burgers.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3d99f6-4b40-42d7-858a-049ef929805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now, we need to create a training data where input is [(u0, u1, u2, u3, ...., u50)] and\n",
    "output is [(u1, u2, u3,....., u51)]\n",
    "'''\n",
    "\n",
    "#Creating the input and output training data\n",
    "init_timestep = 0\n",
    "end_timestep = 50\n",
    "\n",
    "input_data_NN = output[:,init_timestep,:]\n",
    "output_data_NN = output[:,init_timestep+1,:]\n",
    "\n",
    "for i in range(init_timestep+1, end_timestep):\n",
    "    input_data_NN = jnp.vstack((input_data_NN, output[:,i,:]))\n",
    "    output_data_NN = jnp.vstack((output_data_NN, output[:,i+1,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5e1a50-3633-48ee-9597-fb36aa93b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training and testing data split\n",
    "input_data_NN_train, input_data_NN_test, output_data_NN_train, output_data_NN_test = \\\n",
    "                        train_test_split(input_data_NN, output_data_NN, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd6262f-592d-4f48-a935-4d24bdb17d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility class for defining the branch network\n",
    "class branch_net(nn.Module):\n",
    "    branch_layer_config: Sequence[int]\n",
    "    activation: Callable\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        init = nn.initializers.glorot_normal()\n",
    "        \n",
    "        #Branch network forward pass\n",
    "        for i, layer_size in enumerate(self.branch_layer_config[:-1]):\n",
    "            x = nn.Dense(layer_size, kernel_init = init)(x)\n",
    "            x = self.activation(x)\n",
    "        x = nn.Dense(self.branch_layer_config[-1], kernel_init = init)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc97cc8-0485-4185-a51f-95851f4234ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility class for defining the trunk network\n",
    "class trunk_net(nn.Module):\n",
    "    trunk_layer_config: Sequence[int]\n",
    "    activation: Callable\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        init = nn.initializers.glorot_normal()\n",
    "        \n",
    "        #Trunk network forward pass\n",
    "        for i, layer_size in enumerate(self.trunk_layer_config):\n",
    "            x = nn.Dense(layer_size, kernel_init = init)(x)\n",
    "            x = self.activation(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70f3871-80bf-4ed2-a5f2-340bbabba519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the DeepONet model\n",
    "class DeepONet(nn.Module):\n",
    "\n",
    "    branch_net_config: Sequence[int]\n",
    "    trunk_net_config: Sequence[int]\n",
    "\n",
    "    def setup(self):\n",
    "\n",
    "        self.branch_net = branch_net(self.branch_net_config, nn.activation.tanh)\n",
    "        self.trunk_net = trunk_net(self.trunk_net_config, nn.activation.tanh)\n",
    "\n",
    "\n",
    "    def __call__(self, x_branch, x_trunk):\n",
    "        \n",
    "        #Vectorize over multiple samples of input functions\n",
    "        branch_outputs = jax.vmap(self.branch_net, in_axes = 0)(x_branch)\n",
    "        \n",
    "        #Vectorize over multiple query points\n",
    "        trunk_outputs = jax.vmap(self.trunk_net, in_axes = 0)(x_trunk)       \n",
    "        \n",
    "        inner_product = jnp.einsum('ik,jk->ij', branch_outputs, trunk_outputs)\n",
    "\n",
    "        return inner_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9117d69-6281-41a6-957b-c0f47f13fb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Form branch and trunk inputs train\n",
    "grid = jnp.linspace(0, 1, 101)[:,jnp.newaxis]    #Grid only takes spatial coordinates for trunk input\n",
    "branch_inputs_train = input_data_NN_train\n",
    "trunk_inputs_train = grid\n",
    "outputs_train = output_data_NN_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee09a242-f615-4daa-8fea-4231f7bd33b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For branch and trunk inputs test\n",
    "branch_inputs_test = input_data_NN_test\n",
    "trunk_inputs_test = grid\n",
    "outputs_test = output_data_NN_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f62bf29-38a0-4836-9928-05526e73e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DeepONet settings\n",
    "\n",
    "#Define the latent dimension at the output of branch/trunk net\n",
    "latent_vector_size = 60\n",
    "\n",
    "#Create the branch and trunk layer configurations\n",
    "branch_network_layer_sizes = [101] + [100]*6 + [latent_vector_size]\n",
    "trunk_network_layer_sizes = [100]*6 + [latent_vector_size]\n",
    "\n",
    "#Instantiate the DeepONet model\n",
    "model = DeepONet(branch_network_layer_sizes, trunk_network_layer_sizes)\n",
    "\n",
    "#Create a jitted model forward function\n",
    "model_fn = jax.jit(model.apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3e022e-b5b7-4ca7-8e3c-d247959d3f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility function to save model params\n",
    "def save_model_params(params, path, filename):\n",
    "    \n",
    "    #Create output directory for saving model params\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    \n",
    "    save_path = os.path.join(path, filename)\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(params, f)\n",
    "\n",
    "#Utility function to load model params\n",
    "def load_model_params(path, filename):\n",
    "    load_path = os.path.join(path, filename)\n",
    "    with open(load_path, 'rb') as f:\n",
    "        params = pickle.load(f)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f276557b-b782-4dc7-85b8-86d5e1a23a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def loss_fn(params, branch_inputs, trunk_inputs, gt_outputs, dt=0.01):\n",
    "    \n",
    "    u_curr = branch_inputs  # Current state input (e.g., u(t))\n",
    "    u_next = gt_outputs     # Ground truth next state (e.g., u(t+1))\n",
    "    \n",
    "    #Without time integrator use DeepONet to predict next timestep\n",
    "    u_pred_next = model_fn(params, u_curr, trunk_inputs)\n",
    "\n",
    "    # Compute the Mean Squared Error loss between the predicted and ground truth next states\n",
    "    mse_loss = jnp.mean(jnp.square(u_pred_next - u_next))\n",
    "    \n",
    "    return mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae0a5a3-aa17-4258-be0b-b7f8bcb21ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def update(params, branch_inputs, trunk_inputs, gt_outputs, opt_state):\n",
    "    loss, grads = jax.value_and_grad(loss_fn)(params, branch_inputs, trunk_inputs, gt_outputs)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    \n",
    "    return params, opt_state, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c917ac8-a0aa-4019-852c-69844d19ecc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model parameters\n",
    "key = jax.random.PRNGKey(42)\n",
    "params = model.init(key, branch_inputs_train[0:1, ...], trunk_inputs_train[0:1, ...])\n",
    "\n",
    "# Optimizer setup\n",
    "lr_scheduler = optax.schedules.exponential_decay(init_value = 1e-3, transition_steps = 5000, decay_rate=0.95)\n",
    "optimizer = optax.adam(learning_rate=lr_scheduler)\n",
    "opt_state = optimizer.init(params)\n",
    "\n",
    "training_loss_history = []\n",
    "test_loss_history = []\n",
    "num_epochs = int(1e5)\n",
    "batch_size = 256\n",
    "\n",
    "min_test_loss = jnp.inf\n",
    "\n",
    "filepath = 'DeepONet_Autoregressive_Burgers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bd9180-c123-4dc4-bec9-6bfe8c78c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(num_epochs), desc=\"Training progress\"):\n",
    "\n",
    "    #Perform mini-batching\n",
    "    shuffled_indices = jax.random.permutation(jax.random.PRNGKey(epoch), branch_inputs_train.shape[0])\n",
    "    batch_indices = shuffled_indices[:batch_size]\n",
    "\n",
    "    branch_inputs_train_batch = branch_inputs_train[batch_indices]\n",
    "    outputs_train_batch = outputs_train[batch_indices]\n",
    "\n",
    "    # Update the parameters and optimizer state\n",
    "    params, opt_state, loss = update(\n",
    "        params=params,\n",
    "        branch_inputs=branch_inputs_train_batch,\n",
    "        trunk_inputs=trunk_inputs_train,\n",
    "        gt_outputs=outputs_train_batch,\n",
    "        opt_state=opt_state\n",
    "    )\n",
    "\n",
    "    #Keep a track of the train loss\n",
    "    training_loss_history.append(loss)\n",
    "    \n",
    "    #Do predictions on the test data simultaneously\n",
    "    test_mse_loss = loss_fn(params = params, \n",
    "                            branch_inputs = branch_inputs_test, \n",
    "                            trunk_inputs = trunk_inputs_test, \n",
    "                            gt_outputs = outputs_test)\n",
    "    test_loss_history.append(test_mse_loss)\n",
    "    \n",
    "    #Save the params of the best model encountered till now\n",
    "    if test_mse_loss < min_test_loss:\n",
    "        best_params = params\n",
    "        save_model_params(best_params, path = filepath, filename = 'model_params_best.pkl')\n",
    "        min_test_loss = test_mse_loss\n",
    "    \n",
    "    #Print the train and test loss history every 1000 epochs\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch: {epoch}, training_loss_MSE: {loss}, test_loss_MSE: {test_mse_loss}, \\\n",
    "                                best_test_loss_MSE: {min_test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4ff64a-1e79-4ed4-a5bb-2a21603f5f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the train and test loss histories\n",
    "plt.figure(dpi = 130)\n",
    "plt.semilogy(np.arange(epoch+1), training_loss_history, label = \"Train loss\")\n",
    "plt.semilogy(np.arange(epoch+1), test_loss_history, label = \"Test loss\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.tick_params(which = 'major', axis = 'both', direction = 'in', length = 6)\n",
    "plt.tick_params(which = 'minor', axis = 'both', direction = 'in', length = 3.5)\n",
    "plt.minorticks_on()\n",
    "\n",
    "plt.grid(alpha = 0.3)\n",
    "plt.legend(loc = 'best')\n",
    "plt.savefig(filepath + \"/loss_plot.jpeg\", dpi = 800)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301c7f61-8e07-45d0-8330-7529f3a7e5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the loss arrays\n",
    "np.save(\"Train_loss.npy\",training_loss_history)\n",
    "np.save(\"Test_loss.npy\",test_loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7411a447-6de2-440d-adf2-231371cc986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility function for doing inference for a single timestep\n",
    "@jax.jit\n",
    "def inference(u_curr, trunk_inputs_test, dt=0.01):\n",
    "    \n",
    "    u_next = model_fn(best_params, u_curr, trunk_inputs_test)\n",
    "    \n",
    "    return u_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f13c6c-a50e-43a6-a982-f9259cdaeecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility function for doing inference for all timesteps\n",
    "def run_inference(initial_u, trunk_inputs_test, n_steps, dt=0.01):\n",
    "    u_states = np.zeros_like(output)  # Array to store the states over time\n",
    "    u_states[:,0,:] = initial_u\n",
    "    \n",
    "    u_curr = initial_u  # Set the current state to the initial state\n",
    "    \n",
    "    for i in range(1, n_steps):\n",
    "        # Perform one inference step\n",
    "        u_next = inference(u_curr, trunk_inputs_test, dt)\n",
    "        \n",
    "        # Assign the predicted state\n",
    "        u_states[:, i, :] = u_next\n",
    "        \n",
    "        # Update current state for the next step\n",
    "        u_curr = u_next\n",
    "    \n",
    "    return u_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f6a482-e70e-443e-b7b5-b052963d433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model parameters\n",
    "best_params = load_model_params(path=filepath, filename='model_params_best.pkl')\n",
    "\n",
    "#Start with u(t=0, x)\n",
    "u_curr = output[:, 0, :]\n",
    "\n",
    "#Perform inferencing\n",
    "u_pred = run_inference(u_curr, trunk_inputs_test, n_steps=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c407e788-e24a-4e33-8c8e-aafb336a63d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly selecting \"size\" number of samples out of the test dataset\n",
    "indices = np.random.choice(np.arange(output.shape[0]), size = 3, replace = 'True')\n",
    "\n",
    "x_test = jnp.linspace(0,1,101)\n",
    "t_test = jnp.linspace(0,1,101)\n",
    "\n",
    "for idx in indices:\n",
    "    plt.figure(figsize = (12,3))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    contour1 = plt.contourf(x_test, t_test, u_pred[idx, :, :], levels = 20, cmap = 'jet')\n",
    "    plt.xlabel(\"x\", fontsize = 14)\n",
    "    plt.ylabel(\"t\", fontsize = 14)\n",
    "    plt.yticks(fontsize = 12)\n",
    "    plt.xticks(fontsize = 12)\n",
    "    cbar1 = plt.colorbar()\n",
    "    cbar1.ax.tick_params(labelsize=12)\n",
    "    plt.title(\"Predicted\", fontsize = 16)\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    contour2 = plt.contourf(x_test, t_test, output[idx, :, :], levels = 20, cmap = 'jet')\n",
    "    plt.xlabel(\"x\", fontsize = 14)\n",
    "    plt.ylabel(\"t\", fontsize = 14)\n",
    "    plt.xticks(fontsize = 12)\n",
    "    plt.yticks(fontsize = 12)\n",
    "    cbar2 = plt.colorbar()\n",
    "    cbar2.ax.tick_params(labelsize=12)\n",
    "    plt.title(\"Actual\", fontsize=16)\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    contour3 = plt.contourf(x_test, t_test, jnp.abs(u_pred[idx, :, :] - output[idx, :, :]), cmap = 'Wistia')\n",
    "    plt.xlabel(\"x\", fontsize = 14)\n",
    "    plt.ylabel(\"t\", fontsize = 14)\n",
    "    plt.xticks(fontsize = 12)\n",
    "    plt.yticks(fontsize = 12)\n",
    "    cbar3 = plt.colorbar()\n",
    "    cbar3.ax.tick_params(labelsize=12)\n",
    "    plt.title(\"Error\", fontsize = 16)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(filepath + f\"/Contour_plots_sidx_{idx}.jpeg\", dpi = 800)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5a9b1f-4728-4a95-85a6-c08f969f346d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plotting the relative L2 error obtained at every timestep to show accummulation of autoregressive error\n",
    "\n",
    "auto_reg_error = []\n",
    "num_time_steps = 101\n",
    "\n",
    "for i in range(num_time_steps):\n",
    "    l2_error = jnp.linalg.norm(u_pred[:,i,:] - output[:,i,:])/jnp.linalg.norm(output[:,i,:])\n",
    "    auto_reg_error.append(l2_error)\n",
    "\n",
    "plt.figure(figsize =(5,3.5))\n",
    "plt.plot(jnp.linspace(0, 1, 101), auto_reg_error, color = \"blue\", marker='o', markersize=1, linestyle='-')\n",
    "plt.xlabel(\"Time (t)\", fontsize = 14)\n",
    "plt.ylabel(\"Relative L2 error\", fontsize = 14)\n",
    "\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "\n",
    "plt.tick_params(axis = \"both\", which = \"major\", length = 6, direction = \"in\")\n",
    "plt.tick_params(axis = \"both\", which = \"minor\", length = 3.5, direction = \"in\")\n",
    "plt.minorticks_on()\n",
    "\n",
    "plt.grid(which=\"major\", axis=\"both\", alpha=0.6, linestyle='-')\n",
    "plt.grid(which=\"minor\", axis=\"both\", alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.savefig(filepath + \"/Error_acc.jpeg\", dpi=800)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a680f42c-df46-4042-9871-79971f16fd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the auto_reg_error array for comparing with TI approach\n",
    "save = True\n",
    "if save:\n",
    "    np.save(filepath + \"/Auto_reg_error_without_TI.npy\", auto_reg_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf50b58d-c81b-4547-b464-22bc802535a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the predictions and ground truth outputs\n",
    "\n",
    "np.save(filepath + \"/u_pred.npy\", u_pred)\n",
    "np.save(filepath + \"/u_actual.npy\", output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
