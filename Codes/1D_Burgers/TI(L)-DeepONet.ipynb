{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2c3477-9a71-4a31-89d1-6b52d1ca8d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries\n",
    "import os, sys, pickle\n",
    "import jax, jaxlib\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "import optax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Callable, Sequence\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bad965-3b98-4f2c-9348-5953f823ff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Burgers dataset\n",
    "burgers = loadmat(\"Burger.mat\")\n",
    "output = burgers['output']\n",
    "burgers.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b30cde1-58c5-41d2-9a47-c93f9b547894",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now, we need to create a training data where input is [(u0, u1, u2, u3, ...., u50)] and\n",
    "output is [(u1, u2, u3,....., u51)]\n",
    "'''\n",
    "\n",
    "#Creating the input and output training data\n",
    "init_timestep = 0\n",
    "end_timestep = 50\n",
    "\n",
    "input_data_NN = output[:,init_timestep,:]\n",
    "output_data_NN = output[:,init_timestep+1,:]\n",
    "\n",
    "for i in range(init_timestep+1, end_timestep):\n",
    "    input_data_NN = jnp.vstack((input_data_NN, output[:,i,:]))\n",
    "    output_data_NN = jnp.vstack((output_data_NN, output[:,i+1,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a8e0be-26bb-4e55-96fc-49d285afc04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the training and testing data splits\n",
    "input_data_NN_train, input_data_NN_test, output_data_NN_train, output_data_NN_test = \\\n",
    "                        train_test_split(input_data_NN, output_data_NN, test_size = 0.2, random_state = 42)\n",
    "input_data_NN_train.shape, input_data_NN_test.shape, output_data_NN_train.shape, output_data_NN_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e45dec-523f-4643-80ab-a39664895065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility class for defining the branch network\n",
    "class branch_net(nn.Module):\n",
    "    branch_layer_config: Sequence[int]\n",
    "    activation: Callable\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        init = nn.initializers.glorot_normal()\n",
    "        \n",
    "        #Branch network forward pass\n",
    "        for i, layer_size in enumerate(self.branch_layer_config[:-1]):\n",
    "            x = nn.Dense(layer_size, kernel_init = init)(x)\n",
    "            x = self.activation(x)\n",
    "        x = nn.Dense(self.branch_layer_config[-1], kernel_init = init)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96303dce-7c57-4105-b3d2-02bf329fee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility class for defining the trunk network\n",
    "class trunk_net(nn.Module):\n",
    "    trunk_layer_config: Sequence[int]\n",
    "    activation: Callable\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        init = nn.initializers.glorot_normal()\n",
    "        \n",
    "        #Trunk network forward pass\n",
    "        for i, layer_size in enumerate(self.trunk_layer_config):\n",
    "            x = nn.Dense(layer_size, kernel_init = init)(x)\n",
    "            x = self.activation(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2288c69-dcdd-452c-977e-51046cf151bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the DeepONet model\n",
    "class DeepONet(nn.Module):\n",
    "\n",
    "    branch_net_config: Sequence[int]\n",
    "    trunk_net_config: Sequence[int]\n",
    "\n",
    "    def setup(self):\n",
    "\n",
    "        self.branch_net = branch_net(self.branch_net_config, nn.activation.tanh)\n",
    "        self.trunk_net = trunk_net(self.trunk_net_config, nn.activation.tanh)\n",
    "\n",
    "\n",
    "    def __call__(self, x_branch, x_trunk):\n",
    "        \n",
    "        #Vectorize over multiple samples of input functions\n",
    "        branch_outputs = jax.vmap(self.branch_net, in_axes = 0)(x_branch)\n",
    "        \n",
    "        #Vectorize over multiple query points\n",
    "        trunk_outputs = jax.vmap(self.trunk_net, in_axes = 0)(x_trunk)       \n",
    "        \n",
    "        inner_product = jnp.einsum('ik,jk->ij', branch_outputs, trunk_outputs)\n",
    "\n",
    "        return inner_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24243a0-5d38-4c4c-8c0d-a4e61fe08981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility class for defining the auxiliary NN for getting the learnable RK4 slope coefficients\n",
    "class LearnableRK4(nn.Module):\n",
    "    hidden_dim: int = 32\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, u_curr):\n",
    "        x = u_curr\n",
    "        x = nn.Dense(self.hidden_dim)(x)\n",
    "        x = nn.activation.tanh(x)\n",
    "        x = nn.Dense(self.hidden_dim)(x)\n",
    "        x = nn.activation.tanh(x)\n",
    "        x = nn.Dense(4)(x)\n",
    "        x = nn.activation.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4bc11a-d20b-49a4-b182-b5391a7c6566",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform one adaptive rk4 step\n",
    "def dynamic_rk4_step(u_curr, model_fn, params, model_rk_fn, rk_params, trunk_inputs, dt):\n",
    "    \n",
    "    alpha = jax.vmap(model_rk_fn, in_axes = (None, 0))(rk_params, u_curr)         #(Shape: (batch_size,4)\n",
    "    \n",
    "    #Extract the coefficients  - each with shape (batch_size, 1)\n",
    "    alpha1 = alpha[:,0:1]\n",
    "    alpha2 = alpha[:,1:2]\n",
    "    alpha3 = alpha[:,2:3]\n",
    "    alpha4 = alpha[:,3:]\n",
    "\n",
    "    #Get the RK4 slopes\n",
    "    k1 = model_fn(params, u_curr, trunk_inputs)\n",
    "    k2 = model_fn(params, u_curr + 0.5 * dt * k1, trunk_inputs)\n",
    "    k3 = model_fn(params, u_curr + 0.5 * dt * k2, trunk_inputs)\n",
    "    k4 = model_fn(params, u_curr + dt * k3, trunk_inputs)\n",
    "\n",
    "    #Perform the adaptive RK4 update\n",
    "    u_next = u_curr + dt * (alpha1 * k1 + alpha2 * k2 + alpha3 * k3 + alpha4 * k4)\n",
    "    return u_next, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de1ed67-7782-4865-b7b9-cd2e30f62c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def loss_fn(params, rk_params, branch_inputs, trunk_inputs, gt_outputs, dt=0.01):\n",
    "    \n",
    "    u_curr = branch_inputs  # Current state input (e.g., u(t))\n",
    "    u_next = gt_outputs     # Ground truth next state (e.g., u(t+1))\n",
    "    \n",
    "    u_pred_next, alpha = dynamic_rk4_step(u_curr, model_fn, params, model_rk_fn, rk_params, trunk_inputs, dt)\n",
    "\n",
    "    # Compute the Mean Squared Error loss between the predicted and ground truth next states\n",
    "    mse_loss = jnp.mean(jnp.square(u_pred_next - u_next))\n",
    "    \n",
    "    return (mse_loss, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e17841-8be1-40f8-a2ce-11d5751f7cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def update(params, rk_params, branch_inputs, trunk_inputs, gt_outputs, opt_state, opt_state_rk):\n",
    "    \n",
    "    #Update for DeepONet params\n",
    "    (loss, _), grads = \\\n",
    "            jax.value_and_grad(loss_fn, argnums = 0, has_aux=True)(params, rk_params, branch_inputs, trunk_inputs, gt_outputs)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    \n",
    "    #Update for RK params\n",
    "    (_, alpha), rk_grads = \\\n",
    "        jax.value_and_grad(loss_fn, argnums = 1, has_aux=True)(params, rk_params, branch_inputs, trunk_inputs, gt_outputs)\n",
    "    updates_rk, opt_state_rk = optimizer_rk.update(rk_grads, opt_state_rk)\n",
    "    rk_params = optax.apply_updates(rk_params, updates_rk)\n",
    "    \n",
    "    return params, rk_params, opt_state, opt_state_rk, loss, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1b62a5-5cc6-497f-8db1-ec5ad33a47ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Form branch and trunk inputs train\n",
    "grid = jnp.linspace(0, 1, 101)[:,jnp.newaxis]   #Trunk net takes only spatial coordinates\n",
    "branch_inputs_train = input_data_NN_train\n",
    "trunk_inputs_train = grid\n",
    "outputs_train = output_data_NN_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baed59f1-8d2d-4489-9544-0c10ef87e1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For branch and trunk inputs test\n",
    "branch_inputs_test = input_data_NN_test\n",
    "trunk_inputs_test = grid\n",
    "outputs_test = output_data_NN_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa88bb9-8993-4e35-8bba-92ab72a6ce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DeepONet settings\n",
    "\n",
    "#Define the latent dimension at the output of the branch/trunk network\n",
    "latent_vector_size = 60\n",
    "\n",
    "#Create the branch and trunk layer configurations\n",
    "branch_network_layer_sizes = [101] + [100]*6 + [latent_vector_size]\n",
    "trunk_network_layer_sizes = [100]*6 + [latent_vector_size]\n",
    "\n",
    "#Instantiate the DeepONet model\n",
    "model = DeepONet(branch_network_layer_sizes, trunk_network_layer_sizes)\n",
    "\n",
    "#Create a jitted DeepONet model forward function\n",
    "model_fn = jax.jit(model.apply)\n",
    "\n",
    "#Instantiate the learnable RK4 NN\n",
    "model_rk = LearnableRK4()\n",
    "\n",
    "#Create a jitted learnableRK4 model forward function\n",
    "model_rk_fn = jax.jit(model_rk.apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d041ae7c-e543-4a72-9697-613eae30cc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility function for saving the model params\n",
    "def save_model_params(params, path, filename):\n",
    "    \n",
    "    #Create output directory for saving model params\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    \n",
    "    save_path = os.path.join(path, filename)\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(params, f)\n",
    "\n",
    "#Utility function for loading the model params\n",
    "def load_model_params(path, filename):\n",
    "    load_path = os.path.join(path, filename)\n",
    "    with open(load_path, 'rb') as f:\n",
    "        params = pickle.load(f)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc71764-30ac-4e16-9395-ab9b3783602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model parameters\n",
    "key = jax.random.PRNGKey(42)\n",
    "key, subkey = jax.random.split(key)\n",
    "\n",
    "#Initialize all the network params - DeepONet and learnable RK4 NN\n",
    "params = model.init(key, branch_inputs_train, trunk_inputs_train)\n",
    "rk_params = model_rk.init(subkey, branch_inputs_train)\n",
    "\n",
    "# Optimizer setup\n",
    "\n",
    "#Initialize optimizer for DeepONet\n",
    "lr_scheduler = optax.schedules.exponential_decay(init_value=1e-3, transition_steps=5000, decay_rate=0.95)\n",
    "optimizer = optax.adam(learning_rate=lr_scheduler)\n",
    "opt_state = optimizer.init(params)\n",
    "\n",
    "#Initialize optimizer for learnable RK4 NN\n",
    "lr_scheduler = optax.schedules.exponential_decay(init_value=1e-3, transition_steps=5000, decay_rate=0.95)\n",
    "optimizer_rk = optax.adam(learning_rate=lr_scheduler)\n",
    "opt_state_rk = optimizer_rk.init(rk_params)\n",
    "\n",
    "training_loss_history = []\n",
    "test_loss_history = []\n",
    "num_epochs = int(1e5)\n",
    "batch_size = 256\n",
    "\n",
    "min_test_loss = jnp.inf\n",
    "\n",
    "filepath = 'TI-DON_Burgers_learnableRK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7f1176-64da-4a1a-8501-98105f783299",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_lst = []\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "\n",
    "    #Perform mini-batching\n",
    "    shuffled_indices = jax.random.permutation(jax.random.PRNGKey(epoch), input_data_NN.shape[0])\n",
    "    batch_indices = shuffled_indices[:batch_size]\n",
    "\n",
    "    branch_inputs_train_batch = branch_inputs_train[batch_indices]\n",
    "    outputs_train_batch = outputs_train[batch_indices]\n",
    "\n",
    "    # Update the parameters and optimizer state\n",
    "    params, rk_params, opt_state, opt_state_rk, loss, alpha = update(\n",
    "        params=params,\n",
    "        rk_params=rk_params,\n",
    "        branch_inputs=branch_inputs_train_batch,\n",
    "        trunk_inputs=trunk_inputs_train,\n",
    "        gt_outputs=outputs_train_batch,\n",
    "        opt_state=opt_state,\n",
    "        opt_state_rk=opt_state_rk\n",
    "    )\n",
    "    #Keep a track of the training loss\n",
    "    training_loss_history.append(loss)\n",
    "    alpha_lst.append(alpha)\n",
    "    \n",
    "    #Do predictions on the test data simultaneously\n",
    "    \n",
    "    test_mse_loss, _ = loss_fn(params = params, \n",
    "                            rk_params = rk_params,\n",
    "                            branch_inputs = branch_inputs_test, \n",
    "                            trunk_inputs = trunk_inputs_test, \n",
    "                            gt_outputs = outputs_test)\n",
    "    test_loss_history.append(test_mse_loss)\n",
    "    \n",
    "    #Save the params of the best model encountered till now\n",
    "    if test_mse_loss < min_test_loss:\n",
    "        best_params = {\"deeponet_params\": params, \"rk_params\": rk_params}\n",
    "        save_model_params(best_params, path = filepath, filename = 'model_params_best.pkl')\n",
    "        min_test_loss = test_mse_loss\n",
    "    \n",
    "    #Print the train and test loss history every 1000 epochs\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch: {epoch}, training_loss_MSE: {loss}, test_loss_MSE: {test_mse_loss}, \\\n",
    "                                best_test_loss_MSE: {min_test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa8ea00-ff2f-4080-b9e1-df9d61a712ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the train and test loss histories\n",
    "plt.figure(dpi = 130)\n",
    "plt.semilogy(np.arange(epoch+1), training_loss_history, label = \"Train loss\")\n",
    "plt.semilogy(np.arange(epoch+1), test_loss_history, label = \"Test loss\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.tick_params(which = 'major', axis = 'both', direction = 'in', length = 6)\n",
    "plt.tick_params(which = 'minor', axis = 'both', direction = 'in', length = 3.5)\n",
    "plt.minorticks_on()\n",
    "\n",
    "plt.grid(alpha = 0.3)\n",
    "plt.legend(loc = 'best')\n",
    "plt.savefig(filepath + \"/loss_plot.jpeg\", dpi = 800)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca16d3a-8b71-4970-b06d-b67cf11454fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the loss arrays\n",
    "np.save(\"Train_loss.npy\",training_loss_history)\n",
    "np.save(\"Test_loss.npy\",test_loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b79c1b-c568-4a56-8ffd-1a7ee22115e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For plotting the epoch wise learning of the alphas, save the alpha array\n",
    "\n",
    "alpha_epoch_wise_arr = jnp.array(alpha_lst)\n",
    "np.save(filepath + \"/alpha_epoch_wise_arr.npy\", alpha_epoch_wise_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ca5418-ca2b-4067-9941-bfdbb61a40a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Need to modify inferencing code as now we can use the learnt RK4 coefficients and do RK4 in prediction\n",
    "#Instead of AB-AM predictor-corrector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8fbe82-83de-4a81-aa8c-52bcc365783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform one step of inferencing using adaptive RK4\n",
    "@jax.jit\n",
    "def inference(u_curr, trunk_inputs_test, dt=0.01):\n",
    "    u_next = dynamic_rk4_step(u_curr, model_fn, best_params, model_rk_fn, \n",
    "                              best_rk_params, trunk_inputs_test, dt)\n",
    "    return u_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431f55e7-1c35-4463-8899-adbb55796cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility function for doing inference over all timesteps\n",
    "def run_inference(initial_u, trunk_inputs_test, n_steps, dt=0.01):\n",
    "    u_states = np.zeros_like(output)  # Array to store the states over time\n",
    "    u_states[:,0,:] = initial_u\n",
    "    \n",
    "    # Initialize the current state (this could be your u_0 and u_1, etc.)\n",
    "    u_curr = initial_u  # Set the current state to the initial state\n",
    "    \n",
    "    for i in range(1, n_steps):\n",
    "        # Perform one inference step\n",
    "        u_next = inference(u_curr, trunk_inputs_test, dt)\n",
    "        \n",
    "        # Assign the predicted state\n",
    "        u_states[:, i, :] = u_next\n",
    "        \n",
    "        # Update current state for the next step\n",
    "        u_curr = u_next\n",
    "    \n",
    "    return u_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4847ca8d-4db3-406e-a25c-c47f91247568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model parameters\n",
    "best_full_params = load_model_params(path=filepath, filename='model_params_best.pkl')\n",
    "best_params = best_full_params['deeponet_params']\n",
    "best_rk_params = best_full_params['rk_params']\n",
    "\n",
    "#Start with u(t=0, x)\n",
    "u_curr = output[:, 0, :]\n",
    "\n",
    "#Perform inferencing\n",
    "u_pred = run_inference(u_curr, trunk_inputs_test, n_steps=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7096e4ce-ce9a-43e4-afa0-94d3f4de973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly selecting \"size\" number of samples out of the test dataset\n",
    "indices = np.random.choice(np.arange(output.shape[0]), size = 3, replace = 'True')\n",
    "\n",
    "x_test = jnp.linspace(0,1,101)\n",
    "t_test = jnp.linspace(0,1,101)\n",
    "\n",
    "for idx in indices:\n",
    "    plt.figure(figsize = (12,3))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    contour1 = plt.contourf(x_test, t_test, u_pred[idx, :, :], levels = 20, cmap = 'jet')\n",
    "    plt.xlabel(\"x\", fontsize = 14)\n",
    "    plt.ylabel(\"t\", fontsize = 14)\n",
    "    plt.yticks(fontsize = 12)\n",
    "    plt.xticks(fontsize = 12)\n",
    "    cbar1 = plt.colorbar()\n",
    "    cbar1.ax.tick_params(labelsize=12)\n",
    "    plt.title(\"Predicted\", fontsize = 16)\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    contour2 = plt.contourf(x_test, t_test, output[idx, :, :], levels = 20, cmap = 'jet')\n",
    "    plt.xlabel(\"x\", fontsize = 14)\n",
    "    plt.ylabel(\"t\", fontsize = 14)\n",
    "    plt.yticks(fontsize = 12)\n",
    "    plt.xticks(fontsize = 12)\n",
    "    cbar2 = plt.colorbar()\n",
    "    cbar2.ax.tick_params(labelsize=12)\n",
    "    plt.title(\"Actual\", fontsize=16)\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    contour3 = plt.contourf(x_test, t_test, jnp.abs(u_pred[idx, :, :] - output[idx, :, :]), cmap = 'Wistia')\n",
    "    plt.xlabel(\"x\", fontsize = 14)\n",
    "    plt.ylabel(\"t\", fontsize = 14)\n",
    "    plt.yticks(fontsize = 12)\n",
    "    plt.xticks(fontsize = 12)\n",
    "    cbar3 = plt.colorbar()\n",
    "    cbar3.ax.tick_params(labelsize=12)\n",
    "    plt.title(\"Error\", fontsize = 16)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(filepath + f\"/Contour_plots_sidx_{idx}.jpeg\", dpi = 800)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0040c8c7-8822-4033-ad2e-47af9917eec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the relative L2 error obtained at every timestep to show accummulation of autoregressive error\n",
    "\n",
    "auto_reg_error = []\n",
    "num_time_steps = 101\n",
    "\n",
    "for i in range(num_time_steps):\n",
    "    l2_error = jnp.linalg.norm(u_pred[:,i,:] - output[:,i,:])/jnp.linalg.norm(output[:,i,:])\n",
    "    auto_reg_error.append(l2_error)\n",
    "    \n",
    "plt.plot(jnp.arange(num_time_steps), auto_reg_error)\n",
    "plt.xlabel(\"Timesteps\")\n",
    "plt.ylabel(\"Relative L2 error\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb77273-5aae-433d-9261-65bfc4cda887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the auto_reg_error array for comparing with TI approach\n",
    "np.save(filepath + \"/Auto_reg_error_with_TI-DON_learnableRK4.npy\", auto_reg_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48df856-6613-4cb6-8db4-d4d9eafeec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the predictions and ground truth outputs\n",
    "\n",
    "np.save(filepath + \"/u_pred.npy\", u_pred)\n",
    "np.save(filepath + \"/u_actual.npy\", output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
