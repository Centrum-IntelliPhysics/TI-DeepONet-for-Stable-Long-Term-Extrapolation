{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2c3477-9a71-4a31-89d1-6b52d1ca8d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary libraries\n",
    "import os, sys, pickle\n",
    "import jax, jaxlib\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "import optax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Callable, Sequence\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6b59cd-ea7d-4c4f-945e-fe411aec7c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the random seed and create a JAX PRNG Key\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "key = jax.random.PRNGKey(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a380133d-3161-440e-8fe2-154b3453f12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the 2D Burgers' dataset\n",
    "\n",
    "dataset = torch.load(\"Burgers_equation_2D_scalar.pt\")\n",
    "inputs = dataset['input_samples']\n",
    "outputs = dataset['output_samples']     #Ns = 5000, Nt = 101, Nx = 32, Ny = 32\n",
    "\n",
    "inputs = jnp.array(inputs)\n",
    "outputs = jnp.array(outputs)\n",
    "\n",
    "#Consider first 1000 samples due to memory constraints\n",
    "inputs = inputs[:1000, :, :]\n",
    "outputs = outputs[:1000, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7ce333-fd2d-4594-b27d-7b87e6a961ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete the dataset and free up memory\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b702d9c2-876d-4564-9bf7-fbd20a55bbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns, nt, nx, ny = outputs.shape\n",
    "print(f\"ns: {ns}, nt: {nt}, nx: {nx}, ny: {ny}\")\n",
    "\n",
    "'''\n",
    "Now, we need to create a training data where input is [(u0, u1, u2, u3, ...., u33)] and\n",
    "output is [(u1, u2, u3,....., u34)]\n",
    "'''\n",
    "\n",
    "#Creating the input and output training data\n",
    "init_timestep = 0\n",
    "end_timestep = 33\n",
    "\n",
    "input_data_NN = outputs[:, init_timestep, :, :]    \n",
    "output_data_NN = outputs[:, init_timestep+1, :, :]\n",
    "\n",
    "for i in range(init_timestep+1, end_timestep):\n",
    "    input_data_NN = jnp.vstack((input_data_NN, outputs[:,i,:,:]))\n",
    "    output_data_NN = jnp.vstack((output_data_NN, outputs[:,i+1,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582309d0-4215-459a-8d2a-6e6761ca0b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping the output_data_NN from (ns*nt//3, nx, ny) to (ns*nt//3, nx*ny)\n",
    "#Input_data_NN remains as it is, i.e., (ns*nt//3, nx, ny)\n",
    "output_data_NN = output_data_NN.reshape(output_data_NN.shape[0], output_data_NN.shape[1]*output_data_NN.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a8e0be-26bb-4e55-96fc-49d285afc04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the train and test data splits\n",
    "input_data_NN_train, input_data_NN_test, output_data_NN_train, output_data_NN_test = \\\n",
    "                        train_test_split(input_data_NN, output_data_NN, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4ccaed-8699-4e36-9c61-3f5eef95747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeing memory by deleting input_data_NN and output_data_NN\n",
    "del input_data_NN, output_data_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e45dec-523f-4643-80ab-a39664895065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility class for defining the branch network\n",
    "class branch_net(nn.Module):\n",
    "\n",
    "    layer_sizes: Sequence[int] \n",
    "    activation: Callable\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        init = nn.initializers.glorot_normal()\n",
    "        \n",
    "        # #x has shape (ns, nx, ny) - so add channel dimension: (ns, nx, ny, nc)\n",
    "        x = x[..., jnp.newaxis]\n",
    "        \n",
    "        #2D Convolutional layers and pooling layers\n",
    "        x = nn.Conv(features = 64, kernel_size = (3,3), strides = 1, padding = \"SAME\")(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.max_pool(x, window_shape=(2, 2), strides = (2, 2), padding = \"SAME\")\n",
    "        \n",
    "        x = nn.Conv(features = 64, kernel_size = (2, 2), strides = 1, padding = \"SAME\")(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape = (2,2), strides = (2,2), padding = \"SAME\")\n",
    "        \n",
    "        x = x.flatten()   #flattening layer\n",
    "        \n",
    "        #MLP layers\n",
    "        for i, layer in enumerate(self.layer_sizes[:-1]):\n",
    "            x = nn.Dense(layer, kernel_init = init)(x)\n",
    "            x = self.activation(x)\n",
    "        x = nn.Dense(self.layer_sizes[-1], kernel_init = init)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96303dce-7c57-4105-b3d2-02bf329fee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility class for defining the trunk network\n",
    "class trunk_net(nn.Module):\n",
    "    trunk_layer_config: Sequence[int]\n",
    "    activation: Callable\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        init = nn.initializers.glorot_normal()\n",
    "        \n",
    "        #Trunk network forward pass\n",
    "        for i, layer_size in enumerate(self.trunk_layer_config):\n",
    "            x = nn.Dense(layer_size, kernel_init = init)(x)\n",
    "            x = self.activation(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2288c69-dcdd-452c-977e-51046cf151bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the DeepONet model\n",
    "class DeepONet(nn.Module):\n",
    "\n",
    "    branch_net_config: Sequence[int]\n",
    "    trunk_net_config: Sequence[int]\n",
    "\n",
    "    def setup(self):\n",
    "\n",
    "        self.branch_net = branch_net(self.branch_net_config, nn.activation.tanh)\n",
    "        self.trunk_net = trunk_net(self.trunk_net_config, nn.activation.tanh)\n",
    "\n",
    "\n",
    "    def __call__(self, x_branch, x_trunk):\n",
    "        \n",
    "        #Vectorize over multiple samples of input functions\n",
    "        branch_outputs = jax.vmap(self.branch_net, in_axes = 0)(x_branch)\n",
    "        \n",
    "        #Vectorize over multiple query points\n",
    "        trunk_outputs = jax.vmap(self.trunk_net, in_axes = 0)(x_trunk)       \n",
    "        \n",
    "        inner_product = jnp.einsum('ik,jk->ij', branch_outputs, trunk_outputs)\n",
    "\n",
    "        return inner_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ead73ce-1ead-49eb-92f5-e8e00a784ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Form branch and trunk inputs train\n",
    "xspan = jnp.linspace(0, 1, nx)\n",
    "yspan = jnp.linspace(0, 1, ny)\n",
    "\n",
    "#Create for trunk network - a meshgrid of only spatial coordinates\n",
    "[x,y] = jnp.meshgrid(xspan, yspan, indexing = 'ij')\n",
    "grid = jnp.transpose(jnp.array([x.flatten(), y.flatten()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93298730-7d2e-40bc-a09b-4ad4f751e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the training data for branch and trunk inputs\n",
    "branch_inputs_train = input_data_NN_train\n",
    "trunk_inputs_train = grid\n",
    "outputs_train = output_data_NN_train\n",
    "\n",
    "print(\"Shape of branch inputs train: \",branch_inputs_train.shape)\n",
    "print(\"Shape of trunk inputs train: \",trunk_inputs_train.shape)\n",
    "print(\"Shape of outputs train: \",outputs_train.shape)\n",
    "print(\"Shape of grid: \",grid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879dbfd4-5c89-4416-9637-aae1c664ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For branch and trunk inputs test\n",
    "\n",
    "branch_inputs_test = input_data_NN_test\n",
    "trunk_inputs_test = grid\n",
    "outputs_test = output_data_NN_test\n",
    "\n",
    "print(\"Shape of branch inputs test: \",branch_inputs_test.shape)\n",
    "print(\"Shape of trunk inputs test: \",trunk_inputs_test.shape)\n",
    "print(\"Shape of outputs test: \",outputs_test.shape)\n",
    "print(\"Shape of grid: \",grid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa88bb9-8993-4e35-8bba-92ab72a6ce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DeepONet settings\n",
    "\n",
    "#Define the latent dimension at the output of the branch/trunk net\n",
    "latent_vector_size = 100\n",
    "\n",
    "#Create the branch and trunk network layer configurations\n",
    "branch_network_layer_sizes = [256, 128] + [latent_vector_size]\n",
    "trunk_network_layer_sizes = [128]*4 + [latent_vector_size]\n",
    "\n",
    "#Instantiate the DeepONet model\n",
    "model = DeepONet(branch_network_layer_sizes, trunk_network_layer_sizes)\n",
    "\n",
    "#Create a jitted model forward function\n",
    "model_fn = jax.jit(model.apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d041ae7c-e543-4a72-9697-613eae30cc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility function for saving the model params\n",
    "def save_model_params(params, path, filename):\n",
    "    \n",
    "    #Create output directory for saving model params\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    \n",
    "    save_path = os.path.join(path, filename)\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(params, f)\n",
    "\n",
    "#Utility function for loading the model params\n",
    "def load_model_params(path, filename):\n",
    "    load_path = os.path.join(path, filename)\n",
    "    with open(load_path, 'rb') as f:\n",
    "        params = pickle.load(f)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e14732-d308-4f17-8ec4-6732805f9d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def loss_fn(params, branch_inputs, trunk_inputs, gt_outputs, dt=0.01):\n",
    "    \n",
    "    u_curr = branch_inputs  # Current state input (e.g., u(t))\n",
    "    u_next = gt_outputs     # Ground truth next state (e.g., u(t+1))\n",
    "\n",
    "    # Predict the system dynamics (u_dot) at the current state using the model\n",
    "    u_dot = model_fn(params, u_curr, trunk_inputs)  # Model's predicted rate of change\n",
    "\n",
    "    # Implementing the 4th-order Runge-Kutta (RK4) time-stepping method\n",
    "    k1 = u_dot   #(ns*nt, nx*ny)\n",
    "    k1 = k1.reshape(k1.shape[0], nx, ny)   #(ns*nt, nx, ny)\n",
    "    \n",
    "    k2 = model_fn(params, u_curr + 0.5 * dt * k1, trunk_inputs)   #(ns*nt, nx*ny)\n",
    "    k2 = k2.reshape(k2.shape[0], nx, ny)    #(ns*nt, nx, ny)\n",
    "    \n",
    "    k3 = model_fn(params, u_curr + 0.5 * dt * k2, trunk_inputs)     #(ns*nt, nx*ny)\n",
    "    k3 = k3.reshape(k3.shape[0], nx, ny)    #(ns*nt, nx, ny)\n",
    "    \n",
    "    k4 = model_fn(params, u_curr + dt * k3, trunk_inputs)    #(ns*nt, nx*ny)\n",
    "    k4 = k4.reshape(k4.shape[0], nx, ny)    #(ns*nt, nx, ny)\n",
    "    \n",
    "    # Calculate the next state using RK4\n",
    "    u_pred_next = u_curr + (dt / 6) * (k1 + 2 * k2 + 2 * k3 + k4)  #(ns*nt, nx, ny)\n",
    "    \n",
    "    #Reshape u_pred_next to match compatibility of u_next\n",
    "    u_pred_next = u_pred_next.reshape(u_pred_next.shape[0], nx*ny)\n",
    "\n",
    "    # Compute the Mean Squared Error loss between the predicted and ground truth next states\n",
    "    mse_loss = jnp.mean(jnp.square(u_pred_next - u_next))\n",
    "    \n",
    "    return mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7304664c-7c89-4992-bafd-71a85d68a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def update(params, branch_inputs, trunk_inputs, gt_outputs, opt_state):\n",
    "    loss, grads = jax.value_and_grad(loss_fn)(params, branch_inputs, trunk_inputs, gt_outputs)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    \n",
    "    return params, opt_state, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53f0eaf-c539-4856-81d9-d52c40fe169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeing memory by deleting inputs and outputs\n",
    "del inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc71764-30ac-4e16-9395-ab9b3783602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model parameters\n",
    "params = model.init(key, branch_inputs_train[0:1, ...], trunk_inputs_train[0:1, ...])\n",
    "\n",
    "#Initialize optimizer for DeepONet\n",
    "lr_scheduler = optax.schedules.exponential_decay(init_value=1e-3, transition_steps=5000, decay_rate=0.95)\n",
    "optimizer = optax.adam(learning_rate=lr_scheduler)\n",
    "opt_state = optimizer.init(params)\n",
    "\n",
    "training_loss_history = []\n",
    "test_loss_history = []\n",
    "num_epochs = int(1.2e5)\n",
    "batch_size = 64\n",
    "\n",
    "min_test_loss = jnp.inf\n",
    "\n",
    "filepath = 'TI-DON_2D_Burgers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7f1176-64da-4a1a-8501-98105f783299",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(num_epochs), desc=\"Training Progress\"):\n",
    "\n",
    "    #Perform mini-batching\n",
    "    shuffled_indices = jax.random.permutation(jax.random.PRNGKey(epoch), branch_inputs_train.shape[0])\n",
    "    batch_indices = shuffled_indices[:batch_size]\n",
    "\n",
    "    branch_inputs_train_batch = branch_inputs_train[batch_indices]\n",
    "    outputs_train_batch = outputs_train[batch_indices]\n",
    "\n",
    "    # Update the parameters and optimizer state\n",
    "    params, opt_state, loss = update(\n",
    "        params=params,\n",
    "        branch_inputs=branch_inputs_train_batch,\n",
    "        trunk_inputs=trunk_inputs_train,\n",
    "        gt_outputs=outputs_train_batch,\n",
    "        opt_state=opt_state\n",
    "    )\n",
    "\n",
    "    #Keep a track of the train loss\n",
    "    training_loss_history.append(loss)\n",
    "    \n",
    "    #Do predictions on the test data simultaneously\n",
    "    test_mse_loss = loss_fn(params = params, \n",
    "                            branch_inputs = branch_inputs_test, \n",
    "                            trunk_inputs = trunk_inputs_test, \n",
    "                            gt_outputs = outputs_test)\n",
    "    test_loss_history.append(test_mse_loss)\n",
    "    \n",
    "    #Save the params of the best model encountered till now\n",
    "    if test_mse_loss < min_test_loss:\n",
    "        best_params = params\n",
    "        save_model_params(best_params, path = filepath, filename = 'model_params_best.pkl')\n",
    "        min_test_loss = test_mse_loss\n",
    "    \n",
    "    #Print the train and test loss history every 1000 epochs\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch: {epoch}, training_loss_MSE: {loss}, test_loss_MSE: {test_mse_loss}, \\\n",
    "                                best_test_loss_MSE: {min_test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e28c329-52cd-435f-a152-f242a64de368",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the train and test loss histories\n",
    "plt.figure(dpi = 130)\n",
    "plt.semilogy(np.arange(epoch+1), training_loss_history, label = \"Train loss\")\n",
    "plt.semilogy(np.arange(epoch+1), test_loss_history, label = \"Test loss\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.tick_params(which = 'major', axis = 'both', direction = 'in', length = 6)\n",
    "plt.tick_params(which = 'minor', axis = 'both', direction = 'in', length = 3.5)\n",
    "plt.minorticks_on()\n",
    "\n",
    "plt.grid(alpha = 0.3)\n",
    "plt.legend(loc = 'best')\n",
    "plt.savefig(filepath + \"/loss_plot.jpeg\", dpi = 800)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74806900-dc24-4cf6-a2b9-9d929492c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the loss arrays\n",
    "np.save(filepath + \"/Train_loss.npy\",training_loss_history)\n",
    "np.save(filepath + \"/Test_loss.npy\",test_loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea9aeb-514a-40be-bd29-e63d10c14761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do one AB2/AM3 inference step\n",
    "@jax.jit\n",
    "def inference_ab(u_curr, u_prev, trunk_inputs_test, dt=0.01):\n",
    "    # Step 1: Apply the predictor (Adams-Bashforth) using u_curr and u_prev\n",
    "    u_dot_curr = model_fn(best_params, u_curr, trunk_inputs_test)  # Predict the rate of change at u_curr\n",
    "    u_dot_prev = model_fn(best_params, u_prev, trunk_inputs_test)  # Predict the rate of change at u_prev\n",
    "    \n",
    "    #Reshaping u_dot_curr and u_dot_prev to broadcast compatible with u_curr\n",
    "    u_dot_curr = u_dot_curr.reshape(u_dot_curr.shape[0], nx, ny)\n",
    "    u_dot_prev = u_dot_prev.reshape(u_dot_prev.shape[0], nx, ny)\n",
    "    \n",
    "    \n",
    "    # Adams-Bashforth predictor (using previous two points)\n",
    "    u_pred = u_curr + dt * (1.5 * u_dot_curr - 0.5 * u_dot_prev)\n",
    "    \n",
    "    # Step 2: Apply the corrector (Adams-Moulton) using the predicted u_pred\n",
    "    u_dot_pred = model_fn(best_params, u_pred, trunk_inputs_test)  # Predict the rate of change at u_pred\n",
    "    \n",
    "    #Reshaping u_dot_pred to broadcast compatible with u_curr, u_dot_curr, u_dot_prev\n",
    "    u_dot_pred = u_dot_pred.reshape(u_dot_pred.shape[0], nx, ny)\n",
    "    \n",
    "    # Adams-Moulton corrector (refine the prediction using u_pred)\n",
    "    u_next = u_curr + dt * (5/12 * u_dot_pred + 8/12 * u_dot_curr - 1/12 * u_dot_prev)\n",
    "    \n",
    "    return u_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b77e24-4d62-48f6-859f-86a9ff691fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do one RK4 inference step\n",
    "@jax.jit\n",
    "def inference_rk(u_curr, trunk_inputs_test, dt = 0.01):\n",
    "    \n",
    "    # Predict the system dynamics (u_dot) at the current state using the model\n",
    "    u_dot = model_fn(params, u_curr, trunk_inputs_test)  # Model's predicted rate of change\n",
    "\n",
    "    # Implementing the 4th-order Runge-Kutta (RK4) time-stepping method\n",
    "    k1 = u_dot   #(ns*nt, nx*ny)\n",
    "    k1 = k1.reshape(k1.shape[0], nx, ny)   #(ns*nt, nx, ny)\n",
    "    \n",
    "    k2 = model_fn(params, u_curr + 0.5 * dt * k1, trunk_inputs_test)   #(ns*nt, nx*ny)\n",
    "    k2 = k2.reshape(k2.shape[0], nx, ny)    #(ns*nt, nx, ny)\n",
    "    \n",
    "    k3 = model_fn(params, u_curr + 0.5 * dt * k2, trunk_inputs_test)     #(ns*nt, nx*ny)\n",
    "    k3 = k3.reshape(k3.shape[0], nx, ny)    #(ns*nt, nx, ny)\n",
    "    \n",
    "    k4 = model_fn(params, u_curr + dt * k3, trunk_inputs_test)    #(ns*nt, nx*ny)\n",
    "    k4 = k4.reshape(k4.shape[0], nx, ny)    #(ns*nt, nx, ny)\n",
    "    \n",
    "    # Calculate the next state using RK4\n",
    "    u_pred_next = u_curr + (dt / 6) * (k1 + 2 * k2 + 2 * k3 + k4)  #(ns*nt, nx, ny)\n",
    "    \n",
    "    return u_pred_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914401c5-833d-4831-b87f-5a3b5ca7f114",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility function for perform inferencing over all timesteps\n",
    "def run_inference(initial_u, trunk_inputs_test, n_steps, method, dt=0.01):\n",
    "    u_states = np.zeros(shape = (ns, nt, nx, ny))  # Array to store the states over time\n",
    "    u_states[:,0,:,:] = initial_u\n",
    "    \n",
    "    # Initialize the previous state (this could be your u_0 and u_1, etc.)\n",
    "    u_prev = initial_u  # Set the previous state to the initial state\n",
    "    u_curr = initial_u  # Set the current state to the initial state\n",
    "    \n",
    "    for i in range(1, n_steps):\n",
    "        \n",
    "        if method == \"AB\":\n",
    "            # Perform one inference step using the Adams-Bashforth method\n",
    "            u_next = inference_ab(u_curr, u_prev, trunk_inputs_test, dt)\n",
    "\n",
    "            # Assign the predicted state\n",
    "            u_states[:, i, :, :] = u_next\n",
    "\n",
    "            # Update previous and current states for the next step\n",
    "            u_prev = u_curr\n",
    "            u_curr = u_next\n",
    "        \n",
    "        elif method == \"RK\":\n",
    "            #Perform one inference step using the RK-4 method\n",
    "            u_next = inference_rk(u_curr, trunk_inputs_test, dt)\n",
    "            \n",
    "            # Assign the predicted state\n",
    "            u_states[:, i, :, :] = u_next\n",
    "            \n",
    "            #Update the current state for the next step\n",
    "            u_curr = u_next\n",
    "    \n",
    "    return u_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4847ca8d-4db3-406e-a25c-c47f91247568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model parameters\n",
    "best_params = load_model_params(path=filepath, filename='model_params_best.pkl')\n",
    "\n",
    "#Reload the relevant datasets afresh for performing inference\n",
    "dataset = torch.load(\"Burgers_equation_2D_scalar.pt\")\n",
    "inputs = dataset['input_samples']\n",
    "outputs = dataset['output_samples']\n",
    "\n",
    "inputs = jnp.array(inputs)\n",
    "outputs = jnp.array(outputs)\n",
    "\n",
    "#Consider first 1000 samples due to memory constraints\n",
    "inputs = inputs[:1000, :, :]\n",
    "outputs = outputs[:1000, :, :]\n",
    "\n",
    "del dataset\n",
    "\n",
    "method = \"AB\"\n",
    "\n",
    "#Start with u(t-0, x, y)\n",
    "u_curr = outputs[:, 0, :, :]\n",
    "\n",
    "#Perform inference\n",
    "u_pred = run_inference(u_curr, trunk_inputs_test, n_steps=nt, method = method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7096e4ce-ce9a-43e4-afa0-94d3f4de973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly selecting \"size\" number of samples out of the test dataset\n",
    "indices = np.random.choice(np.arange(u_pred.shape[0]), size = 3, replace = 'False')\n",
    "\n",
    "x_test = jnp.linspace(0, 1, nx)\n",
    "y_test = jnp.linspace(0, 1, ny)\n",
    "t_test = jnp.linspace(0, 1, nt)\n",
    "\n",
    "t_query = [25, 50, -1]\n",
    "\n",
    "for idx in indices:\n",
    "    \n",
    "    for t in t_query:\n",
    "        plt.figure(figsize = (12,3))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        contour1 = plt.contourf(x_test, y_test, u_pred[idx, t, :, :], levels = 20, cmap = 'jet')\n",
    "        plt.xlabel(\"x\", fontsize = 14)\n",
    "        plt.ylabel(\"t\", fontsize = 14)\n",
    "        plt.yticks(fontsize = 12)\n",
    "        plt.xticks(fontsize = 12)\n",
    "        cbar1 = plt.colorbar()\n",
    "        cbar1.ax.tick_params(labelsize=12)\n",
    "        plt.title(\"Predicted\", fontsize = 16)\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        contour2 = plt.contourf(x_test, y_test, outputs[idx, t, :, :], levels = 20, cmap = 'jet')\n",
    "        plt.xlabel(\"x\", fontsize = 14)\n",
    "        plt.ylabel(\"t\", fontsize = 14)\n",
    "        plt.xticks(fontsize = 12)\n",
    "        plt.yticks(fontsize = 12)\n",
    "        cbar2 = plt.colorbar()\n",
    "        cbar2.ax.tick_params(labelsize=12)\n",
    "        plt.title(\"Actual\", fontsize=16)\n",
    "\n",
    "        plt.subplot(1,3,3)\n",
    "        contour3 = plt.contourf(x_test, y_test, jnp.abs(u_pred[idx,t, :, :] - \n",
    "                                                        outputs[idx,t, :, :]), cmap = 'Wistia')\n",
    "        plt.xlabel(\"x\", fontsize = 14)\n",
    "        plt.ylabel(\"t\", fontsize = 14)\n",
    "        plt.xticks(fontsize = 12)\n",
    "        plt.yticks(fontsize = 12)\n",
    "        cbar3 = plt.colorbar()\n",
    "        cbar3.ax.tick_params(labelsize=12)\n",
    "        plt.title(\"Error\", fontsize = 16)\n",
    "        \n",
    "        plt.suptitle(f\"Sample Idx: {idx}, Timestep: {t}\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.savefig(filepath + f\"/Contour_plots_sidx_{idx}_{method}.jpeg\", dpi = 800)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0040c8c7-8822-4033-ad2e-47af9917eec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the relative L2 error obtained at every timestep to show accummulation of autoregressive error\n",
    "\n",
    "auto_reg_error = []\n",
    "num_time_steps = nt\n",
    "\n",
    "for i in range(num_time_steps):\n",
    "    l2_error = jnp.linalg.norm(u_pred[:,i,:,:] - outputs[:,i,:,:])/jnp.linalg.norm(outputs[:,i,:,:])\n",
    "    auto_reg_error.append(l2_error)\n",
    "    \n",
    "plt.plot(jnp.arange(num_time_steps), auto_reg_error)\n",
    "plt.xlabel(\"Timesteps\")\n",
    "plt.ylabel(\"Relative L2 error\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb77273-5aae-433d-9261-65bfc4cda887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the auto_reg_error array for comparing with TI approach\n",
    "np.save(filepath + f\"/Auto_reg_error_with_TI-DON_{method}.npy\", auto_reg_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a8c4cb-1fe1-4a35-a7c9-a21948e6685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the u_pred and ground truth output arrays for separate postprocessing\n",
    "\n",
    "save = True\n",
    "if save:\n",
    "    np.save(filepath + f\"/u_pred_{method}.npy\", u_pred)\n",
    "    np.save(filepath + f\"/actual_{method}.npy\", outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
